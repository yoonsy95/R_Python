{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN(Convolutional Neural Network)\n",
    "\n",
    "# FC layer(Fully Connected layer)\n",
    "# 이전 layer의 모든 node가 다음 layer의 모든 node에 연결되면 학습되는 layer구조\n",
    "# FC layer를 다른 말로 Dense layer라고도 함\n",
    "\n",
    "# 지금까지 우리가 작업한 신경망은 모두 FC layer를 이용하고 있음\n",
    "\n",
    "# FC layer의 특징은 MNIST의 예제처럼 입력데이터가 1차원으로 한정됨\n",
    "# 즉, 각각의 이미지가 1차원으로 표현되어야 함\n",
    "# 그래서 2차원 이미지를 1차원으로 변환시켜서 사용한 것\n",
    "\n",
    "# 우리가 사용한 MNIST예제는 상당히 간단한 이미지 학습, 예측 예제임\n",
    "\n",
    "# 이미지 학습의 가장 큰 문제는\n",
    "# 이미지가 살짝 휘어있거나 크기가 제각각이거나 변형이 조금만 생겨도 학습이 힘들어짐\n",
    "\n",
    "# 이런 경우 training data가 굉정히 많이 필요하고 추가적으로 학습할 때 많은 시간을 요구하기 됨\n",
    "\n",
    "#############################################\n",
    "\n",
    "# 고민하면서 사람이 학습하는 방식 모델림 함\n",
    "# 찾아낸 방법은 이미지의 픽셀값을 그대로 입력하는게 아닌\n",
    "# 이 이미지를 대표하는 특징을 도출하여 신경망에 여러 개 넣어서 학습하는 방식\n",
    "\n",
    "# 1장의 컬러사진은 width, height, color(depth) 3차원으로 표현\n",
    "# 여러장의 사진이 사용되기에 입력데이터는 4차원으로 표현\n",
    "\n",
    "# 실제 이미지 1장은 3차원이고 이걸 flatten시켜서 1차원으로 표현해야 함\n",
    "# 크기를 조절해야 되기에 공간에 대한 데이터를 유실할 우려가 있음\n",
    "# 이런 데이터 유실 때문에 학습과 예측에 문제가 발생하게 됨\n",
    "\n",
    "# 공간데이터의 유실을 없어고, 이미지의 특성을 추출, 학습이 용이하게 만드는 방식 ==> CNN\n",
    "# (하나의 원본이미지를 원본의 특성을 가지고 있는 홀더 혹은 이미지로 여러개 만든다)\n",
    "\n",
    "# 3차원 데이터에 필터를 적용 => 적용될 필터도 3차원 필터 지님\n",
    "# width, height은 아무렇게나 지정 가능하나 depth는 원본과 동일한 값을 지녀야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (1, 3, 3, 1)\n",
      "weight shape: (2, 2, 1, 3)\n",
      "conv2d shape: (1, 2, 2, 3)\n",
      "pool shape: (1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# code로 알아보자\n",
    "# 사용되어지는 함수부터 알아봅세\n",
    "# Sample CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 입력데이터의 형식: 3*3*1   이미지 1개 이용\n",
    "# 입력데이터 => (이미지개수. width, height, color) => (1,3,3,1)\n",
    "# 총 9개의 데이터가 사용(1~9)\n",
    "image=np.array([[[[1],[2],[3]],\n",
    "                 [[4],[5],[6]],\n",
    "                 [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(f'image shape: {image.shape}')   # (1,3,3,1)\n",
    "\n",
    "# Activation map을 위한 filter를 정의 (width, height, depth(color), filter 개수)\n",
    "# filter (2,2,1,3) // (2,2,1) * 3\n",
    "weight=np.array([[[[1,10,-1]],[[1,10,-1]]],\n",
    "                 [[[1,10,-1]],[[1,10,-1]]]])\n",
    "print(f'weight shape: {weight.shape}')   # (2,2,1,3)\n",
    "\n",
    "# stride=1 (가로, 세로를 1씩 움직여요)\n",
    "conv2d=tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='VALID')\n",
    "# strides => 배열 맞춰주어야 함,\n",
    "#            가로세로 크기 같게 맞출 것\n",
    "#            [1] => 가로, [2] => 세로\n",
    "#            [0],[3] => dummy\n",
    "# padding='VALID' => padding X\n",
    "#         'SAME'  => padding O\n",
    "print(f'conv2d shape: {conv2d.shape}')   # (1, 2, 2, 3)\n",
    "                                         # (img 개수, 가로, 세로, filter?)\n",
    "sess=tf.Session()\n",
    "conv2d=sess.run(conv2d)\n",
    "\n",
    "# ReLu 들어감\n",
    "\n",
    "# pooling layer\n",
    "pool=tf.nn.max_pool(conv2d, ksize=[1,2,2,1],\n",
    "                    strides=[1,1,1,1], padding='SAME')\n",
    "# ksize => kernel size( [1],[2] )\n",
    "#          [0],[3] => dummy\n",
    "print(f'pool shape: {pool.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "img shape: (1, 28, 28, 1)\n",
      "conv2d shape: (1, 14, 14, 50)\n",
      "conv2d_img shape: (50, 14, 14, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d03b02f978>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution 결과 이미지가 원본 이미지에 비해 어떻게 다른가!?\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Loading\n",
    "mnist=input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "img=mnist.train.images[39512].reshape(28,28)\n",
    "plt.imshow(img, cmap='Greys')\n",
    "\n",
    "###############################################\n",
    "# 해당 이미지 convolution 처리 해 보죠\n",
    "# 입력데이터 => (이미지 개수, width, height, color) => (1,3,3,1)\n",
    "img=img.reshape(-1,28,28,1)\n",
    "print(f'img shape: {img.shape}')\n",
    "\n",
    "# Activation map을 위한 filter 정의\n",
    "# (width, height, color, filter 개수)\n",
    "W=tf.Variable(tf.random_normal([3,3,1,50]), name='filter1')\n",
    "\n",
    "conv2d=tf.nn.conv2d(img, W, strides=[1,2,2,1],padding='SAME')\n",
    "print(f'conv2d shape: {conv2d.shape}')   # (1, 14, 14, 5)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d=sess.run(conv2d)\n",
    "\n",
    "# 이미지를 표현하기 위하여 축을 전환\n",
    "# (1,14,14,5) => (5,14,14,1)\n",
    "conv2d_img=np.swapaxes(conv2d,0,3)\n",
    "print(f'conv2d_img shape: {conv2d_img.shape}') \n",
    "plt.imshow(conv2d_img[4].reshape(14,14), cmap='Greys')  # [4] => filter 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# tensorflow-MNIST with CNN\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Data Loading\n",
    "mnist=input_data.read_data_sets('./data/mnist', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost value1: 0.6142646074295044\n",
      "cost value2: 0.18215391039848328\n",
      "cost value3: 0.6505834460258484\n",
      "cost value4: 0.08644069731235504\n",
      "cost value5: 0.125531867146492\n",
      "cost value6: 0.15061932802200317\n",
      "cost value7: 0.31346338987350464\n",
      "cost value8: 0.2664753198623657\n",
      "cost value9: 0.134915292263031\n",
      "cost value10: 0.2140946388244629\n"
     ]
    }
   ],
   "source": [
    "# Graph 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "keep_rate=tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Convolution Layer  (img 개수, width, height, depth)\n",
    "x_img=tf.reshape(X,[-1,28,28,1])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([3,3,1,32]))  # 32 => CHANNEL\n",
    "L1=tf.nn.conv2d(x_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "L1=tf.nn.relu(L1)\n",
    "# pooling\n",
    "L1=tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_rate)\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([3,3,32,64]))\n",
    "L2=tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2=tf.nn.relu(L2)\n",
    "# pooling\n",
    "L2=tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_rate)\n",
    "\n",
    "# 이렇게 만든 데이터를 FC Layer에 넣어서 학습해야 함\n",
    "L2=tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "W3=tf.get_variable('weight3', shape=[7*7*64,256],\n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1=tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1=tf.nn.relu(tf.matmul(L2,W3)+b1)\n",
    "layer1=tf.nn.dropout(_layer1,keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "W4=tf.get_variable('weight4',\n",
    "                   shape=[256,10],\n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2=tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "# Hypothesis\n",
    "logit=tf.matmul(layer1,W4)+b2\n",
    "H=tf.nn.relu(logit)\n",
    "\n",
    "# Cost\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                               labels=Y))\n",
    "\n",
    "# train\n",
    "train=tf.train.AdamOptimizer(learning_rate=.01).minimize(cost)\n",
    "\n",
    "# session & initializer\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# learning\n",
    "cnt=0\n",
    "num_of_epoch=30  # 반복 횟수\n",
    "batch_size=100   # data size\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter=int(mnist.train.num_examples/batch_size)  # 몇 번 반복?\n",
    "    cost_val=0   # 초기화, 안해도 됨\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val=sess.run([train, cost], feed_dict={X:batch_x,\n",
    "                                                       Y:batch_y,\n",
    "                                                       keep_rate:.7})\n",
    "    \n",
    "    if step%3==0:\n",
    "        cnt+=1\n",
    "        print(f'cost value{cnt}: {cost_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9861000180244446\n"
     ]
    }
   ],
   "source": [
    "# accuracy 측정\n",
    "predict=tf.argmax(H,1)\n",
    "correct=tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(f'Accuracy: {sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_rate:1})}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*7*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
