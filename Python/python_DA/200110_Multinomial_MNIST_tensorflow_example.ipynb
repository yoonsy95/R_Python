{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기억해야 할 것 몇 개?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금 사용하고 있는 tensorflow는 cpu버전\n",
    "# deep learning으로 가면 더 많은 수학적 연산(matrix연산)이 필요하고\n",
    "# GPU를 이용하면 더 빠르게 계산할 수 있음\n",
    "# 새로운 가상환경을 만들어서 tensorflow GPU 버전을 이용해 보자\n",
    "# GPU가 nvidia, g-force 계열이어야 // 버전이 같아야\n",
    "\n",
    "# 1. 새로운 가상환경을 하나 생성해야 함\n",
    "#    conda create -n gpu_env python=3.6 openssl\n",
    "# 2. 새로운 가상환경 진입\n",
    "#    activate gpu_env\n",
    "# 3. nb_conda 설치 // default\n",
    "#    conda install nb_conda\n",
    "# 4. 이름 나오도록 등록\n",
    "#    python -m ipykernel install --user --name=gpu_env --display-name=[GPU_ENV]\n",
    "# 5. 최신 비디오 드라이버 설치(NVIDIA)\n",
    "# 6. CUDA 설치(NVIDIA) // tf와 버전 같아야 함\n",
    "# 7. cudnn 압출풀어서 덮어쓰기(C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. learning rate\n",
    "# 정해져 있는 값은 없음\n",
    "# .01을 기준으로 cost 값을 보고 learning rate를 조절\n",
    "# 만약 learning rate가 너무 크다면 => overshooting 현상 발생\n",
    "# 만약 learning rate가 너무 작다면 => local minimun 현상이 발생\n",
    "# cost값을 기준으로 커스터마이징을 해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 입력데이터의 preprecessing\n",
    "# feature engineering을 포함해서 각 feature의 데이터의 범주와 크기를 살펴봐야 함\n",
    "# 정규화,(Normalization): Min Max Scale을 이용\n",
    "# 표준화(standardization): 평균과 표준편차를 이용하여 -1 ~ 1사이의 값으로 scale하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting(과적합)\n",
    "# 모델을 만들어서 학습을 하는데 학습데이터에 너무 잘 들어맞는 모델이 생성되는 경우\n",
    "# 실제 데이터를 적용할 때 결과값 예측이 잘 안되는 경우를 의미\n",
    "\n",
    "# overfitting을 피하려면\n",
    "# 1. (상당히)많은 training data set이 있어야 함 // 데이터 작을수록 overfitting 잘 일어남\n",
    "# 2. feature 개수를 가능한 줄여야 함\n",
    "#    필요없거나 중복되는 컬럼 삭제,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습과정에서는\n",
    "# 일반적으로 training data set의 크기가 굉장히 큼\n",
    "# 1 epoch을 수행하는 시간이 오래걸리므로 batch처리를 이용해서 학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정\n",
    "# 일반적으로 raw data set을 우리가 얻게되면\n",
    "# training data set과 test data set으로 분리(7:3, 8:2)\n",
    "# n fold cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
